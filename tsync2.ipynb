{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the tsync2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/2710 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 2710/2710 [00:00<00:00, 11430.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing filtered sentences...\n",
      "Writing unfiltered sentences...\n",
      "\n",
      "Created CSV files:\n",
      "1. Filtered sentences: tsync2/processed/combined_tsync2_thai_sentences.csv (2709 sentences)\n",
      "2. Unfiltered sentences: tsync2/processed/combined_tsync2_thai_sentences_no_filter.csv (2710 sentences)\n",
      "Filtered out sentences: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_folder = \"tsync2/wrd_ph\"\n",
    "output_file = \"tsync2/processed/combined_tsync2_thai_sentences.csv\"\n",
    "output_file_no_filter = \"tsync2/processed/combined_tsync2_thai_sentences_no_filter.csv\"\n",
    "\n",
    "# Create lists to store sentences\n",
    "thai_sentences_filtered = []\n",
    "thai_sentences_unfiltered = []\n",
    "\n",
    "# Get list of files first\n",
    "files = sorted([f for f in os.listdir(input_folder) if f.endswith('.txt')])\n",
    "\n",
    "# Process each .txt file in the input directory with progress bar\n",
    "for filename in tqdm(files, desc=\"Processing files\"):\n",
    "    input_path = os.path.join(input_folder, filename)\n",
    "    \n",
    "    # Read the input file\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    # Process only the first line which contains the Thai text\n",
    "    if content:\n",
    "        # Process each word and add to sentence\n",
    "        thai_sentence = ''.join([word for word in content[0].strip().split('|') if word])\n",
    "        \n",
    "        # Add the Thai sentence if not empty\n",
    "        if thai_sentence:\n",
    "            # Always add to unfiltered list\n",
    "            thai_sentences_unfiltered.append([thai_sentence])\n",
    "            \n",
    "            # Add to filtered list only if it doesn't contain ๆ or ฯ\n",
    "            if 'ๆ' not in thai_sentence and 'ฯ' not in thai_sentence:\n",
    "                thai_sentences_filtered.append([thai_sentence])\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Write filtered sentences to CSV\n",
    "print(\"\\nWriting filtered sentences...\")\n",
    "with open(output_file, 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['thai sentence'])  # Header\n",
    "    writer.writerows(thai_sentences_filtered)\n",
    "\n",
    "# Write unfiltered sentences to CSV\n",
    "print(\"Writing unfiltered sentences...\")\n",
    "with open(output_file_no_filter, 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['thai sentence'])  # Header\n",
    "    writer.writerows(thai_sentences_unfiltered)\n",
    "\n",
    "print(f\"\\nCreated CSV files:\")\n",
    "print(f\"1. Filtered sentences: {output_file} ({len(thai_sentences_filtered)} sentences)\")\n",
    "print(f\"2. Unfiltered sentences: {output_file_no_filter} ({len(thai_sentences_unfiltered)} sentences)\")\n",
    "print(f\"Filtered out sentences: {len(thai_sentences_unfiltered) - len(thai_sentences_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phonemize the combined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with phonemes saved as tsync2/processed/combined_tsync2_thai_sentences_phoneme.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Transliterate.transliterate.phonemizer import ThaiPhonemizer, setup_espeak\n",
    "\n",
    "# Set up eSpeak library path\n",
    "_ESPEAK_LIBRARY = '/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib'\n",
    "setup_espeak(_ESPEAK_LIBRARY)\n",
    "    \n",
    "# Initialize phonemizer\n",
    "thai_phonemizer = ThaiPhonemizer()\n",
    "\n",
    "# Input and output file names\n",
    "input_file = \"tsync2/processed/combined_tsync2_thai_sentences.csv\"\n",
    "output_file = \"tsync2/processed/combined_tsync2_thai_sentences_phoneme.csv\"\n",
    "\n",
    "try:\n",
    "  # Read the CSV file\n",
    "  df = pd.read_csv(input_file)\n",
    "\n",
    "  # Generate phonemes for Thai sentences\n",
    "  df[\"thai phoneme\"] = df[\"thai sentence\"].apply(\n",
    "    lambda x: \" \".join(thai_phonemizer.phonemize(x)) if pd.notnull(x) else \"Error in Thai sentence\"\n",
    "  )\n",
    "\n",
    "  # Save to the output file\n",
    "  df.to_csv(output_file, index=False)\n",
    "  print(f\"File with phonemes saved as {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "  print(f\"Error processing file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
