{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file saved as combined_sentences.csv\n",
      "Combined file without filter saved as combined_sentences_no_filter.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder containing the CSV files and the output file name\n",
    "input_folder = \"generated\"\n",
    "output_file = \"combined_sentences.csv\"\n",
    "output_file_no_filter = \"combined_sentences_no_filter.csv\"\n",
    "\n",
    "# List to store dataframes from all files\n",
    "dataframes = []\n",
    "dataframes_no_filter = []\n",
    "\n",
    "# Loop through all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        try:\n",
    "            # Read the CSV file without headers\n",
    "            df = pd.read_csv(file_path, header=None, names=[\"thai sentence\", \"english sentence\"])\n",
    "            \n",
    "            # Remove rows where \"thai sentence\" contains \"ๆ\" or \"ฯ\"\n",
    "            df_no_filter = df.copy()\n",
    "            df = df[~df[\"thai sentence\"].str.contains(r\"[ๆฯ]\", na=False)]\n",
    "            \n",
    "            # Add the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "            dataframes_no_filter.append(df_no_filter)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Save to the output file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined file saved as {output_file}\")\n",
    "else:\n",
    "    print(\"No valid CSV files found in the folder.\")\n",
    "\n",
    "# Combine all dataframes without filter\n",
    "if dataframes_no_filter:\n",
    "    combined_df_no_filter = pd.concat(dataframes_no_filter, ignore_index=True)\n",
    "\n",
    "    # Save to the output file\n",
    "    combined_df_no_filter.to_csv(output_file_no_filter, index=False)\n",
    "    print(f\"Combined file without filter saved as {output_file_no_filter}\")\n",
    "else:\n",
    "    print(\"No valid CSV files found in the folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phonemize the combined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with phonemes saved as combined_sentences_with_phoneme.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Transliterate.transliterate.tokenizer import EnglishTokenizer, ThaiTokenizer, setup_espeak\n",
    "\n",
    "# Set up eSpeak library path\n",
    "_ESPEAK_LIBRARY = '/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib'\n",
    "setup_espeak(_ESPEAK_LIBRARY)\n",
    "\n",
    "# Initialize tokenizers\n",
    "english_tokenizer = EnglishTokenizer()\n",
    "thai_tokenizer = ThaiTokenizer()\n",
    "\n",
    "# Input and output file names\n",
    "input_file = \"combined_sentences.csv\"\n",
    "output_file = \"combined_sentences_with_phoneme.csv\"\n",
    "\n",
    "try:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Generate phonemes for Thai and English sentences\n",
    "    df[\"thai phoneme\"] = df[\"thai sentence\"].apply(\n",
    "        lambda x: \" \".join(thai_tokenizer.phonemize(x)) if pd.notnull(x) else \"Error in Thai sentence\"\n",
    "    )\n",
    "    df[\"english phoneme\"] = df[\"english sentence\"].apply(\n",
    "        lambda x: \" \".join(english_tokenizer.phonemize(x)) if pd.notnull(x) else \"Error in English sentence\"\n",
    "    )\n",
    "\n",
    "    # Save to the output file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"File with phonemes saved as {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing file: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
